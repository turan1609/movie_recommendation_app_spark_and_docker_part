{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a2fe283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/30 15:14:08 WARN Utils: Your hostname, turan-Dell-G15-5511 resolves to a loopback address: 127.0.1.1; using 172.17.30.206 instead (on interface wlp0s20f3)\n",
      "25/06/30 15:14:08 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/30 15:14:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession başlatıldı. Spark Sürümü: 3.5.1\n",
      "SparkContext mevcut: MovieLens32M Recommender\n",
      "\n",
      "'./movies.csv' dosyasından filmler yükleniyor...\n",
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n",
      "Toplam film sayısı: 86537\n",
      "+-------+----------------------------------+-------------------------------------------+\n",
      "|movieId|title                             |genres                                     |\n",
      "+-------+----------------------------------+-------------------------------------------+\n",
      "|1      |Toy Story (1995)                  |Adventure|Animation|Children|Comedy|Fantasy|\n",
      "|2      |Jumanji (1995)                    |Adventure|Children|Fantasy                 |\n",
      "|3      |Grumpier Old Men (1995)           |Comedy|Romance                             |\n",
      "|4      |Waiting to Exhale (1995)          |Comedy|Drama|Romance                       |\n",
      "|5      |Father of the Bride Part II (1995)|Comedy                                     |\n",
      "+-------+----------------------------------+-------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Film ID ve başlıkları sözlüğü oluşturuluyor...\n",
      "86537 film başlığı sözlüğe eklendi.\n",
      "Örnek: Film ID 1 -> Toy Story (1995)\n",
      "\n",
      "'./ratings.csv' dosyasından derecelendirmeler yükleniyor...\n",
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam derecelendirme sayısı (ham): 33832162\n",
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating| timestamp|\n",
      "+------+-------+------+----------+\n",
      "|     1|      1|   4.0|1225734739|\n",
      "|     1|    110|   4.0|1225865086|\n",
      "|     1|    158|   4.0|1225733503|\n",
      "|     1|    260|   4.5|1225735204|\n",
      "|     1|    356|   5.0|1225735119|\n",
      "+------+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "ALS için hazırlanan ratings DataFrame'i:\n",
      "root\n",
      " |-- user: integer (nullable = true)\n",
      " |-- item: integer (nullable = true)\n",
      " |-- rating: float (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam derecelendirme sayısı (işlenmiş): 33832162\n",
      "+----+----+------+\n",
      "|user|item|rating|\n",
      "+----+----+------+\n",
      "|   1|   1|   4.0|\n",
      "|   1| 110|   4.0|\n",
      "|   1| 158|   4.0|\n",
      "|   1| 260|   4.5|\n",
      "|   1| 356|   5.0|\n",
      "+----+----+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Veri seti eğitim ve test olarak bölünüyor (80% eğitim, 20% test)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eğitim seti boyutu: 27063996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test seti boyutu: 6768166\n",
      "\n",
      "ALS modeli eğitiliyor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/30 15:14:37 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALS modeli başarıyla eğitildi.\n"
     ]
    }
   ],
   "source": [
    "# Gerekli Kütüphaneler\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf # DataFrame işlemleri için\n",
    "from pyspark.sql.types import IntegerType, FloatType, StringType, StructType, StructField # DataFrame şemaları için\n",
    "from pyspark.ml.recommendation import ALS # MLlib'in DataFrame tabanlı ALS'si\n",
    "from pyspark.ml.evaluation import RegressionEvaluator # Model değerlendirme için\n",
    "import time\n",
    "import pandas as pd # Küçük veri işlemleri ve kullanıcı girdisi için (opsiyonel)\n",
    "\n",
    "# 1. SparkSession Başlatma\n",
    "# Spark 2.0 ve sonrası için SparkSession ana giriş noktasıdır.\n",
    "# MLlib'in DataFrame tabanlı API'sini kullanmak için SparkSession daha uygundur.\n",
    "spark = (SparkSession.builder\n",
    "    .appName(\"MovieLens32M Recommender\")\n",
    "    .config(\"spark.driver.memory\", \"4g\") # Sürücü belleğini artırabiliriz (veri büyüklüğüne göre)\n",
    "    .config(\"spark.executor.memory\", \"4g\") # Yürütücü belleğini artırabiliriz\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\") # Büyük veri için shuffle partition sayısını ayarlayabiliriz\n",
    "    .master(\"local[*]\") # Tüm yerel çekirdekleri kullan\n",
    "    .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext # Eski RDD tabanlı API'ler için SparkContext'e erişim\n",
    "print(f\"SparkSession başlatıldı. Spark Sürümü: {spark.version}\")\n",
    "print(f\"SparkContext mevcut: {sc.appName}\")\n",
    "\n",
    "# 2. Dosya Yolları (Bu yolları kendi sisteminize göre güncelleyin)\n",
    "# ml-32m klasörünün notebook dosyanızla aynı dizinde olduğunu varsayıyorum.\n",
    "base_path = \"./\" # Veya tam yolunu verin\n",
    "movies_filepath = base_path + \"movies.csv\"\n",
    "ratings_filepath = base_path + \"ratings.csv\"\n",
    "# tags_filepath = base_path + \"tags.csv\" # Bu örnekte kullanmayacağız ama yolu hazır\n",
    "# links_filepath = base_path + \"links.csv\" # Bu örnekte kullanmayacağız ama yolu hazır\n",
    "\n",
    "# 3. Veri Yükleme ve Ön İşleme\n",
    "\n",
    "# Movies Verisini Yükleme (DataFrame olarak)\n",
    "print(f\"\\n'{movies_filepath}' dosyasından filmler yükleniyor...\")\n",
    "# Şemayı manuel olarak tanımlamak, Spark'ın doğru tipleri çıkarmasına yardımcı olur\n",
    "movie_schema = StructType([\n",
    "    StructField(\"movieId\", IntegerType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"genres\", StringType(), True)\n",
    "])\n",
    "\n",
    "movies_df = spark.read.csv(movies_filepath, header=True, schema=movie_schema, escape=\"\\\"\") # escape=\"\\\"\" başlıkta veya türlerde virgül varsa\n",
    "movies_df.printSchema()\n",
    "print(f\"Toplam film sayısı: {movies_df.count()}\")\n",
    "movies_df.show(5, truncate=False)\n",
    "\n",
    "# Film ID'lerini ve Başlıklarını bir sözlüğe alalım (kullanıcı arayüzü için)\n",
    "# Büyük bir DataFrame için collect() dikkatli kullanılmalı, ancak film sayısı (~87k) yönetilebilir olabilir.\n",
    "# Daha büyükse, bu sözlüğü broadcast edebilir veya join ile kullanabiliriz.\n",
    "print(\"\\nFilm ID ve başlıkları sözlüğü oluşturuluyor...\")\n",
    "try:\n",
    "    movie_titles_list = movies_df.select(\"movieId\", \"title\").collect()\n",
    "    titles = {row.movieId: row.title for row in movie_titles_list}\n",
    "    titles_to_ids = {row.title: row.movieId for row in movie_titles_list}\n",
    "    print(f\"{len(titles)} film başlığı sözlüğe eklendi.\")\n",
    "    print(f\"Örnek: Film ID 1 -> {titles.get(1)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Film başlıkları sözlüğü oluşturulurken hata: {e}\")\n",
    "    titles = {}\n",
    "    titles_to_ids = {}\n",
    "\n",
    "# Ratings Verisini Yükleme (DataFrame olarak)\n",
    "print(f\"\\n'{ratings_filepath}' dosyasından derecelendirmeler yükleniyor...\")\n",
    "rating_schema = StructType([\n",
    "    StructField(\"userId\", IntegerType(), True),\n",
    "    StructField(\"movieId\", IntegerType(), True),\n",
    "    StructField(\"rating\", FloatType(), True),\n",
    "    StructField(\"timestamp\", IntegerType(), True) # Timestamp'i şimdilik integer olarak alalım\n",
    "])\n",
    "\n",
    "ratings_df_raw = spark.read.csv(ratings_filepath, header=True, schema=rating_schema)\n",
    "ratings_df_raw.printSchema()\n",
    "print(f\"Toplam derecelendirme sayısı (ham): {ratings_df_raw.count()}\") # Bu işlem zaman alabilir\n",
    "ratings_df_raw.show(5)\n",
    "\n",
    "# MLlib ALS için gerekli sütunları seçelim ve isimlerini değiştirelim (user, item, rating)\n",
    "# userId -> user, movieId -> item\n",
    "ratings_df = ratings_df_raw.select(\n",
    "    col(\"userId\").alias(\"user\"),\n",
    "    col(\"movieId\").alias(\"item\"),\n",
    "    col(\"rating\")\n",
    ").cache() # Sık kullanılacağı için cache'leyelim\n",
    "\n",
    "print(\"\\nALS için hazırlanan ratings DataFrame'i:\")\n",
    "ratings_df.printSchema()\n",
    "print(f\"Toplam derecelendirme sayısı (işlenmiş): {ratings_df.count()}\") # Bu da zaman alabilir\n",
    "ratings_df.show(5)\n",
    "\n",
    "\n",
    "# 4. Veri Setini Eğitim ve Test Olarak Ayırma\n",
    "print(\"\\nVeri seti eğitim ve test olarak bölünüyor (80% eğitim, 20% test)...\")\n",
    "(training_df, test_df) = ratings_df.randomSplit([0.8, 0.2], seed=42) # seed tekrarlanabilirlik için\n",
    "print(f\"Eğitim seti boyutu: {training_df.count()}\")\n",
    "print(f\"Test seti boyutu: {test_df.count()}\")\n",
    "training_df.cache() # Eğitim setini de cache'leyelim\n",
    "test_df.cache()\n",
    "\n",
    "\n",
    "# 5. ALS Modelini Eğitme\n",
    "# Spark ML (DataFrame tabanlı API) içindeki ALS'yi kullanacağız\n",
    "print(\"\\nALS modeli eğitiliyor...\")\n",
    "# Parametreleri belirleyelim (bunlar optimize edilebilir)\n",
    "rank_param = 10       # Gizli faktör sayısı\n",
    "max_iter_param = 10   # Maksimum iterasyon sayısı\n",
    "reg_param = 0.1       # Regülarizasyon parametresi (lambda)\n",
    "alpha_param = 1.0     # Örtük geri bildirim için alfa (bu örnekte explicit feedback kullanıyoruz)\n",
    "\n",
    "als = ALS(userCol=\"user\", itemCol=\"item\", ratingCol=\"rating\",\n",
    "          rank=rank_param,\n",
    "          maxIter=max_iter_param,\n",
    "          regParam=reg_param,\n",
    "          coldStartStrategy=\"drop\", # Yeni kullanıcı/öğe için NaN döndürür, \"nan\" veya \"drop\"\n",
    "          # nonnegative=True, # Faktörlerin negatif olmamasını sağlar (opsiyonel)\n",
    "          implicitPrefs=False) # Derecelendirmelerimiz açık (explicit)\n",
    "\n",
    "# Modeli eğitim verisiyle eğit\n",
    "try:\n",
    "    model = als.fit(training_df)\n",
    "    print(\"ALS modeli başarıyla eğitildi.\")\n",
    "except Exception as e:\n",
    "    print(f\"ALS modeli eğitilirken hata: {e}\")\n",
    "    model = None # Hata durumunda modeli None yap\n",
    "\n",
    "if not model:\n",
    "    print(\"Model eğitilemediği için program sonlandırılıyor.\")\n",
    "    spark.stop()\n",
    "    exit()\n",
    "\n",
    "# ŞİMDİLİK BURAYA KADAR BİR BAŞLANGIÇ.\n",
    "# Buradan sonra arkadaşından girdi alma, modeli güncelleme (veya yeni verilerle birleştirip yeniden eğitme),\n",
    "# tahmin yapma ve tavsiye sunma adımlarını ekleyeceğiz.\n",
    "# Dosyaya ekleme yapmak yerine, yeni derecelendirmeleri bir DataFrame'e dönüştürüp\n",
    "# mevcut training_df ile `union` yaparak modeli yeniden eğitmek daha iyi bir pratik olacaktır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b2962f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Arkadaş Girdileri ---\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Lütfen arkadaşının kullanıcı ID'sini gir (sayısal, önerilen: 330976):  330978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lütfen arkadaşının izlediği filmleri ve verdiği puanları gir (1-5 arası).\n",
      "Bitirmek için film adı yerine 'bitti' yaz.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Film Adı (örn: Toy Story (1995)):  the Godfather\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  UYARI: 'the Godfather' filmi veri setinde bulunamadı. Lütfen tam adını doğru yazdığınızdan emin olun.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Film Adı (örn: Toy Story (1995)):  The Dark Knight (2008)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  UYARI: 'The Dark Knight (2008)' filmi veri setinde bulunamadı. Lütfen tam adını doğru yazdığınızdan emin olun.\n"
     ]
    }
   ],
   "source": [
    "# Gerekli kütüphaneler (ilk hücreden bazıları zaten import edilmiş olabilir)\n",
    "from pyspark.sql.functions import lit, col\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType\n",
    "import pandas as pd\n",
    "\n",
    "# --- Arkadaştan Girdi Alma ---\n",
    "\n",
    "# İlk hücrede 'titles' ve 'titles_to_ids' sözlüklerinin oluşturulduğunu varsayıyoruz.\n",
    "if 'titles_to_ids' not in globals() or not titles_to_ids:\n",
    "    print(\"HATA: 'titles_to_ids' sözlüğü bulunamadı. Lütfen ilk hücreyi çalıştırdığınızdan emin olun.\")\n",
    "else:\n",
    "    print(\"\\n--- Arkadaş Girdileri ---\")\n",
    "    \n",
    "    friend_user_id = None\n",
    "    try:\n",
    "        # Mevcut kullanıcı ID'lerinden daha büyük bir ID atamak iyi bir pratiktir.\n",
    "        # İlk hücredeki ratings_df'ten max kullanıcı id'sini alabiliriz.\n",
    "        max_user_id = ratings_df.selectExpr(\"max(user)\").collect()[0][0]\n",
    "        suggested_id = max_user_id + 1\n",
    "        \n",
    "        friend_user_id_str = input(f\"Lütfen arkadaşının kullanıcı ID'sini gir (sayısal, önerilen: {suggested_id}): \")\n",
    "        friend_user_id = int(friend_user_id_str)\n",
    "    except (ValueError, TypeError):\n",
    "        print(\"Geçersiz kullanıcı ID'si. Lütfen sayısal bir değer girin.\")\n",
    "\n",
    "    friend_new_ratings_list = []\n",
    "    if friend_user_id is not None:\n",
    "        print(\"\\nLütfen arkadaşının izlediği filmleri ve verdiği puanları gir (1-5 arası).\")\n",
    "        print(\"Bitirmek için film adı yerine 'bitti' yaz.\")\n",
    "\n",
    "        while True:\n",
    "            movie_title_input = input(\"Film Adı (örn: Toy Story (1995)): \")\n",
    "            if movie_title_input.lower() == 'bitti':\n",
    "                break\n",
    "            \n",
    "            movie_id = titles_to_ids.get(movie_title_input)\n",
    "            if movie_id is None:\n",
    "                print(f\"  UYARI: '{movie_title_input}' filmi veri setinde bulunamadı. Lütfen tam adını doğru yazdığınızdan emin olun.\")\n",
    "                continue\n",
    "                \n",
    "            while True:\n",
    "                try:\n",
    "                    rating_input_str = input(f\"  '{movie_title_input}' için puanın (1-5): \")\n",
    "                    rating_input = float(rating_input_str)\n",
    "                    if 1.0 <= rating_input <= 5.0:\n",
    "                        # Spark DataFrame'ine uygun bir formatta (user, item, rating) listeye ekliyoruz\n",
    "                        friend_new_ratings_list.append((friend_user_id, movie_id, rating_input))\n",
    "                        print(f\"    '{movie_title_input}' için puan {rating_input} eklendi.\")\n",
    "                        break\n",
    "                    else:\n",
    "                        print(\"  Geçersiz puan. Lütfen 1 ile 5 arasında bir değer girin.\")\n",
    "                except ValueError:\n",
    "                    print(\"  Geçersiz puan formatı. Lütfen sayısal bir değer girin (örn: 4.5).\")\n",
    "\n",
    "    # --- Modeli Yeni Verilerle Güncelleme ve Tavsiye Yapma ---\n",
    "    \n",
    "    if friend_user_id is None or not friend_new_ratings_list:\n",
    "        print(\"\\nKullanıcı ID'si veya derecelendirme alınamadı. Tavsiye adımları atlanıyor.\")\n",
    "    else:\n",
    "        # 1. Yeni derecelendirmelerden bir Spark DataFrame oluştur\n",
    "        # YÖNTEM DEĞİŞİKLİĞİ: Dosyaya yazıp okumak yerine, doğrudan bellekte birleştirmek çok daha verimlidir.\n",
    "        friend_schema = StructType([\n",
    "            StructField(\"user\", IntegerType(), True),\n",
    "            StructField(\"item\", IntegerType(), True),\n",
    "            StructField(\"rating\", FloatType(), True)\n",
    "        ])\n",
    "        friend_ratings_df = spark.createDataFrame(data=friend_new_ratings_list, schema=friend_schema)\n",
    "        \n",
    "        print(\"\\nArkadaşınızın girdiği derecelendirmeler:\")\n",
    "        friend_ratings_df.show()\n",
    "\n",
    "        # 2. Yeni derecelendirmeleri mevcut eğitim setine ekle\n",
    "        print(\"Mevcut eğitim verisi yeni derecelendirmelerle birleştiriliyor...\")\n",
    "        combined_training_df = training_df.union(friend_ratings_df)\n",
    "        combined_training_df.cache() # Yeni birleşim de cache'lenebilir.\n",
    "        \n",
    "        print(f\"Eski eğitim seti boyutu: {training_df.count()}\")\n",
    "        print(f\"Yeni birleşik eğitim seti boyutu: {combined_training_df.count()}\")\n",
    "\n",
    "        # 3. Modeli güncellenmiş veri setiyle YENİDEN EĞİT\n",
    "        # İlk hücredeki 'als' nesnesini kullanarak yeniden fit ediyoruz.\n",
    "        print(\"\\nALS modeli güncel verilerle yeniden eğitiliyor...\")\n",
    "        try:\n",
    "            # YÖNTEM DEĞİŞİKLİĞİ: Eski RDD tabanlı ALS.train() yerine modern DataFrame tabanlı .fit() kullanılıyor.\n",
    "            updated_model = als.fit(combined_training_df)\n",
    "            print(\"ALS modeli başarıyla yeniden eğitildi.\")\n",
    "\n",
    "            # 4. Arkadaşın için tavsiye oluştur\n",
    "            # Önce arkadaşının izlemediği filmleri bulalım\n",
    "            friend_watched_movies_df = friend_ratings_df.select(\"item\").withColumnRenamed(\"item\", \"movieId\")\n",
    "            \n",
    "            # Tüm filmlerden izlenenleri çıkar (bu bir \"anti-join\" işlemidir)\n",
    "            movies_to_recommend_df = movies_df.join(\n",
    "                friend_watched_movies_df,\n",
    "                movies_df.movieId == friend_watched_movies_df.movieId,\n",
    "                \"left_anti\" # Sadece soldaki df'te (movies_df) olup sağdakinde (izlenenler) olmayanları tutar\n",
    "            ).select(col(\"movieId\").alias(\"item\"), lit(friend_user_id).alias(\"user\"))\n",
    "\n",
    "            print(f\"\\nArkadaşınız için {movies_to_recommend_df.count()} adet izlenmemiş film üzerinden tahmin yapılıyor...\")\n",
    "\n",
    "            # 5. İzlenmemiş tüm filmler için tahmin yap\n",
    "            predictions = updated_model.transform(movies_to_recommend_df)\n",
    "\n",
    "            # 6. En yüksek tahminli 10 filmi göster\n",
    "            top_recommendations = predictions.join(movies_df, predictions.item == movies_df.movieId) \\\n",
    "                                             .orderBy(col(\"prediction\").desc()) \\\n",
    "                                             .select(\"title\", \"genres\", \"prediction\") \\\n",
    "                                             .limit(10)\n",
    "            \n",
    "            print(f\"\\n--- Arkadaşın ({friend_user_id}) İçin Top 10 Film Tavsiyesi ---\")\n",
    "            top_recommendations.show(truncate=False)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Model yeniden eğitilirken veya tavsiye oluşturulurken hata oluştu: {e}\")\n",
    "\n",
    "print(\"\\nİnteraktif tavsiye işlemi tamamlandı.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f64a2e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
